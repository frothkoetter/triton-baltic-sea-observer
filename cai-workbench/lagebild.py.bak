import cml.data_v1 as cmldata
from openai import OpenAI
import json
import pandas as pd
from datetime import datetime
from io import StringIO 
import sys # For error logging

# --- Database and Connection Configuration ---
CONNECTION_NAME = "cdw-aw-se-impala"
# NOTE: API_KEY is set in the notebook environment, ensuring compatibility.

# --- LLM Configuration ---
MODEL_ID = "meta/llama-3.3-70b-instruct"

# --- Function Definitions ---

def generate_summary_sql(summary_text, timestamp):
    """
    Generates a single, bulk SQL INSERT statement for the 
    Situation_Awareness_Summary table, separating value sets by comma.
    """
    values = []
    # Format the timestamp for SQL (YYYY-MM-DD HH:MM:SS)
    sql_timestamp = timestamp.strftime("'%Y-%m-%d %H:%M:%S'")
    
    # Split the summary into lines for separate row insertion
    for line_num, line_content in enumerate(summary_text.splitlines()):
        # Skip empty or whitespace-only lines
        if not line_content.strip():
            continue
            
        # Escape single quotes within the content for SQL safety
        escaped_content = line_content.replace("'", "''")
        
        # Create the value tuple: (summary_timestamp, summare_line, summary_text)
        value_tuple = f"({sql_timestamp}, {line_num + 1}, '{escaped_content}')"
        values.append(value_tuple)
    
    if not values:
        return "-- No content generated for insertion."

    # Construct the final single BULK INSERT statement
    insert_statement = (
        "INSERT INTO defense.Situation_Awareness_Summary (summary_timestamp, summare_line, summary_text) VALUES \n"
        + ",\n".join(values) + ";"
    )
        
    return insert_statement

# --- Main Pipeline Execution ---

# Setup Connection and API Client
try:
    conn = cmldata.get_connection(CONNECTION_NAME)
    # The user provided the API_KEY as a string in the prompt; use it directly.
    API_KEY = "eyJqa3UiOiJodHRwczovL3NlLWF3cy1lZGwtZ2F0ZXdheS5zZS1zYW5kYi5hNDY1LTlxNGsuY2xvdWRlcmEuc2l0ZS9zZS1hd3MtZWRsL2hvbWVwYWdlL2tub3h0b2tlbi9hcGkvdjIvandrcy5qc29uIiwia2lkIjoiMUF0VlJRdTZQMHdYS20tYTY5aENxellrbjdCcmx0OTNnU0d3YWlseG5HQSIsInR5cCI6IkpXVCIsImFsZyI6IlJTMjU2In0.eyJzdWIiOiJmcm90aGtvZXR0ZXIiLCJhdWQiOiJjZHAtcHJveHktdG9rZW4iLCJqa3UiOiJodHRwczovL3NlLWF3cy1lZGwtZ2F0ZXdheS5zZS1zYW5kYi5hNDY1LTlxNGsuY2xvdWRlcmEuc2l0ZS9zZS1hd3MtZWRsL2hvbWVwYWdlL2tub3h0b2tlbi9hcGkvdjIvandrcy5qc29uIiwia2lkIjoiMUF0VlJRdTZQMHdYS20tYTY5aENxellrbjdCcmx0OTNnU0d3YWlseG5HQSIsImlzcyI6IktOT1hTU08iLCJleHAiOjE3NjA3Nzk1NjAsIm1hbmFnZWQudG9rZW4iOiJ0cnVlIiwia25veC5pZCI6ImQ2ZDViN2M0LWIwOGQtNGNkOC1hYjhlLTJkNjIyMTE5YjcxZSJ9.GUHux0dVc8mwg7018o5PU77jBeYHjmvm0gcqV0hc966t5T-rdk1B3SRrko8VFQZu5FRyQabQEC3_iP32k0exj8Oma1Hrf_yAwNShcQfid0kw86Hq9f-cufZTX0gSYl-q9XR4sFyDqnTd6Polcl-JxDQRIGWoWVDsdIj8DOhBWe-VNV0j9YCKOZPyuEtubvk-mPqiGVNcfo_yR4dheb6ysAUTeLKUhPzFy85fJIJPCwGepdkFuESH537Wxf45LgIMeZnWuyg6tgAECYXxW-TfUP0qEwwbzg8Zhzo1d2xsVBLqYjdv7scgaJyMx3rSwFgqe5kq6wlZ8F3E7qZWMGBpXQ"
    client = OpenAI(
        base_url="https://ml-0cc463e6-216.se-sandb.a465-9q4k.cloudera.site/namespaces/serving-default/endpoints/llams3370binstruct/v1",
        api_key=API_KEY,
    )
except Exception as e:
    print(f"Failed to initialize connection or API client: {e}")
    sys.exit(1)

# 1. Data Retrieval
try:
    SQL_QUERY = "SELECT * FROM defense.lagebild WHERE harbour_name IN ('Kiel','Rostock','Travem√ºnde','Sasnitz','Stralsund','Wismar')"
    dataframe = conn.get_pandas_dataframe(SQL_QUERY)
    df_content_string = dataframe.to_markdown(index=False)
except Exception as e:
    print(f"Failed to retrieve data from lagebild view: {e}")
    conn.close()
    sys.exit(1)


# 2. Prompt Construction
prompt_template = """
--- MILITARY SITUATION REPORT ---
Analyst: military situation awreness - Please Analyse and provide a concise, pretty summary based on the data below.

Output Format:

Situation Awareness Summary (current data and time ) 

Number of all event analized is 30 recent observations, primarily driven by Buoy and AIS data sources. The analysis identifies Rostock as the primary current hotspot.

1. High-Priority Threat Assessment (Critical) - The single highest-priority event requires immediate investigation
2. Geographic Hotspots and AnomaliesThe most active regions are centered on German ports
3. Conclusion and Recommendation - example Highest Priority: Focus ASW resources immediately on the 0.89 km proximity zone near Rostock to classify the POSSIBLE_SUBMARINE object. Verification: Assign Maritime Patrol Aircraft (MPA) or Unmanned Surface Vessels (USVs) to verify the 203.6 and 157.9 magnetic anomalies reported near Kiel and Rostock.

AIS Sanctions: No vessels with known sanctions were detected in the vicinity of the assessed harbors during this reporting period.

Data:
{}

END OF DATA.
"""
prompt = prompt_template.format(df_content_string)

# 3. LLM Execution Setup
analysis_start_time = datetime.now()
timestamp_str = analysis_start_time.strftime("%Y%m%d_%H%M%S")
report_filename = f"llm_analysis_report_{timestamp_str}.txt"
sql_filename = f"llm_summary_insert_{timestamp_str}.sql"
llm_response_buffer = StringIO()


print(f"Starting analysis and writing report to {report_filename}...")

# 4. LLM Streaming and Capture
try:
    with open(report_filename, 'w', encoding='utf-8') as outfile:
        completion = client.chat.completions.create(
            model=MODEL_ID,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            top_p=0.7,
            max_tokens=2048,
            stream=True
        )
        
        for chunk in completion:
            content = chunk.choices[0].delta.content
            if content is not None:
                outfile.write(content)
                llm_response_buffer.write(content)
                print(".", end="", flush=True)

    llm_summary_text = llm_response_buffer.getvalue()

except Exception as e:
    print(f"\nError during LLM streaming: {e}")
    conn.close()
    sys.exit(1)

# 5. SQL Generation and Execution
try:
    # Generate the bulk INSERT statement
    sql_statement = generate_summary_sql(llm_summary_text, analysis_start_time) 
    
    with conn.get_base_connection() as base_conn:
        with base_conn.cursor() as cursor:
            # 3. Execute the DML statement (INSERT)
            cursor.execute(sql_statement)
            print("Bulk insertion into defense.Situation_Awareness_Summary complete.")    

except Exception as e:
    print(f"\nError during SQL DML Report Insert: {e}")
    
finally:
    # 6. Close the connection
    conn.close()
    print("\nDatabase connection closed.")
